<!DOCTYPE html>
<html lang="zh-cn">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="description" content="简单爬取天眼查指定公司股东信息"/>




  <meta name="keywords" content="python,爬虫," />




  <link rel="alternate" href="/atom.xml" title="Sika">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.6.0" />



<link rel="canonical" href="http://sikasjc.github.io/2017/04/02/pachong/"/>


<meta name="description" content="参考了这篇文章简单爬取天眼查数据（非严谨） 大四了，想找个实习，联系了几家公司，以前没编过爬虫，只了解了些概念，然后有一个公司让我编个爬虫试试看，就是用python实现从天眼查提取指定公司的所有股东，我想了想，编编看，然后完成了这个小东西。">
<meta name="keywords" content="python,爬虫">
<meta property="og:type" content="article">
<meta property="og:title" content="简单爬取天眼查指定公司股东信息">
<meta property="og:url" content="http://sikasjc.github.io/2017/04/02/pachong/index.html">
<meta property="og:site_name" content="Sika">
<meta property="og:description" content="参考了这篇文章简单爬取天眼查数据（非严谨） 大四了，想找个实习，联系了几家公司，以前没编过爬虫，只了解了些概念，然后有一个公司让我编个爬虫试试看，就是用python实现从天眼查提取指定公司的所有股东，我想了想，编编看，然后完成了这个小东西。">
<meta property="og:locale" content="zh-cn">
<meta property="og:image" content="https://i.postimg.cc/Y0d84hn3/0067n1-Rcgy1fe8as329n8j30rr0jn79p.jpg">
<meta property="og:updated_time" content="2018-10-26T15:45:45.080Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="简单爬取天眼查指定公司股东信息">
<meta name="twitter:description" content="参考了这篇文章简单爬取天眼查数据（非严谨） 大四了，想找个实习，联系了几家公司，以前没编过爬虫，只了解了些概念，然后有一个公司让我编个爬虫试试看，就是用python实现从天眼查提取指定公司的所有股东，我想了想，编编看，然后完成了这个小东西。">
<meta name="twitter:image" content="https://i.postimg.cc/Y0d84hn3/0067n1-Rcgy1fe8as329n8j30rr0jn79p.jpg">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.6.0" />







<script>
  var CONFIG = {
    search: ,
    searchPath: "/search.xml",
    fancybox: false,
    toc: true,
  }
</script>




  



    <title> 简单爬取天眼查指定公司股东信息 · Sika </title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">Sika</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            Home
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            Archives
          
        </li>
      </a>
    
      <a href="/tags">
        <li class="mobile-menu-item">
          
          
            Tags
          
        </li>
      </a>
    
      <a href="/categories">
        <li class="mobile-menu-item">
          
          
            Categories
          
        </li>
      </a>
    
      <a href="/about">
        <li class="mobile-menu-item">
          
          
            About
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Sika</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              首页
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              归档
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            
            
              标签
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/categories">
            
            
              分类
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/about">
            
            
              关于
            
          </a>
        </li>
      
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          简单爬取天眼查指定公司股东信息
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017年4月2日
        </span>
      </div>
        
          <div class="post-tags">
            
              <a href="/tags/python/">python</a>
            
              <a href="/tags/爬虫/">爬虫</a>
            
          </div>
        
    </header>

    
    
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#使用seleniumphantomjs获取源代码"><span class="toc-number">1.</span> <span class="toc-text"> 使用selenium+PHANTOMJS获取源代码，</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#为phantomjs添加useragent信息"><span class="toc-number">1.1.</span> <span class="toc-text"> 为phantomjs添加useragent信息</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#获取网页源代码"><span class="toc-number">1.2.</span> <span class="toc-text"> 获取网页源代码</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#使用beautifulsoup4-lxml来解析页面内容"><span class="toc-number">2.</span> <span class="toc-text"> 使用BeautifulSoup4 + lxml来解析页面内容</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#查找指定公司页面url"><span class="toc-number">2.1.</span> <span class="toc-text"> 查找指定公司页面url</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#查找股东页面url"><span class="toc-number">2.2.</span> <span class="toc-text"> 查找股东页面url</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#获得股东信息"><span class="toc-number">2.3.</span> <span class="toc-text"> 获得股东信息</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#整合-全部代码"><span class="toc-number">3.</span> <span class="toc-text"> 整合------全部代码：</span></a></li></ol>
    </div>
  </div>


    <div class="post-content">
      
        <p>参考了这篇文章<a href="https://ask.hellobi.com/blog/jasmine3happy/6200" target="_blank" rel="noopener">简单爬取天眼查数据（非严谨）</a></p>
<p>大四了，想找个实习，联系了几家公司，以前没编过爬虫，只了解了些概念，然后有一个公司让我编个爬虫试试看，就是用python实现从天眼查提取指定公司的所有股东，我想了想，编编看，然后完成了这个小东西。</p>
<a id="more"></a> 
<p>分析天眼查网站，通过火狐抓包，发现必须要解析JavaScript才能拿到真实的数据，网上查找了下，发现使用phantomjs是比较简单的一种方式。</p>
<p>所以选择用selenium 和 phantomjs来获取页面源代码，用BeautifulSoup4 + lxml来解析页面内容，用的python2.7</p>
<h3 id="使用seleniumphantomjs获取源代码"><a class="markdownIt-Anchor" href="#使用seleniumphantomjs获取源代码"></a> 使用selenium+PHANTOMJS获取源代码，</h3>
<p>selenium简单教程-----<a href="http://cuiqingcai.com/2599.html" target="_blank" rel="noopener">Python爬虫利器五之Selenium的用法</a><br>
phantomjs简单教程-----<a href="http://cuiqingcai.com/2577.html" target="_blank" rel="noopener">Python爬虫利器四之PhantomJS的用法</a></p>
<h4 id="为phantomjs添加useragent信息"><a class="markdownIt-Anchor" href="#为phantomjs添加useragent信息"></a> <strong>为phantomjs添加useragent信息</strong></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">driver_open</span><span class="params">()</span>:</span></span><br><span class="line">    dcap = dict(DesiredCapabilities.PHANTOMJS)</span><br><span class="line">    dcap[<span class="string">"phantomjs.page.settings.userAgent"</span>] = (</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0"</span></span><br><span class="line">    )</span><br><span class="line">    driver = webdriver.PhantomJS(desired_capabilities=dcap)</span><br><span class="line">    <span class="keyword">return</span> driver</span><br></pre></td></tr></table></figure>
<h4 id="获取网页源代码"><a class="markdownIt-Anchor" href="#获取网页源代码"></a> <strong>获取网页源代码</strong></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_content</span><span class="params">(driver,url)</span>:</span></span><br><span class="line">    driver.get(url)</span><br><span class="line">    <span class="comment">#等待2秒，根据动态网页加载耗时自定义，这里如果设置的太小的话，会爬取不完整，出现错误</span></span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 获取网页内容</span></span><br><span class="line">    content = driver.page_source.encode(<span class="string">'utf-8'</span>)</span><br><span class="line">    soup = BeautifulSoup(content, <span class="string">'lxml'</span>)</span><br><span class="line">    <span class="keyword">return</span> soup</span><br></pre></td></tr></table></figure>
<p>可以通过 print content 来简单验证页面内容爬的对不对</p>
<h3 id="使用beautifulsoup4-lxml来解析页面内容"><a class="markdownIt-Anchor" href="#使用beautifulsoup4-lxml来解析页面内容"></a> 使用BeautifulSoup4 + lxml来解析页面内容</h3>
<p>BeautifulSoup4教程-----<a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html" target="_blank" rel="noopener">Beautiful Soup 4.2.0 文档</a></p>
<p>接下去解析代码，获取对应的信息。</p>
<h4 id="查找指定公司页面url"><a class="markdownIt-Anchor" href="#查找指定公司页面url"></a> <strong>查找指定公司页面url</strong></h4>
<p>先看天眼查搜索格式<br>
<code>'http://www.tianyancha.com/search?key=' + key + '&amp;checkFrom=searchBox'</code></p>
<p>然后用BeautifulSoup4解析网页源代码<br>
通过urllib.qutoe()方法，以防传入的keyname出现错误编码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">search_url</span><span class="params">(keyname)</span>:</span><span class="comment">#查找公司url</span></span><br><span class="line">    key = urllib.quote(keyname)</span><br><span class="line">    search_url = <span class="string">'http://www.tianyancha.com/search?key='</span> + key + <span class="string">'&amp;checkFrom=searchBox'</span></span><br><span class="line">    res_soup = get_content(driver, search_url) <span class="comment">#得到搜索页代码</span></span><br><span class="line">    ifname = res_soup.find_all(attrs=&#123;<span class="string">"ng-bind-html"</span>: <span class="string">"node.name | trustHtml"</span>&#125;)</span><br><span class="line">    name = ifname[<span class="number">0</span>].text </span><br><span class="line">    ifcompany = res_soup.find_all(attrs=&#123;<span class="string">"ng-click"</span>: <span class="string">"$event.preventDefault();goToCompany(node.id);inClick=true;"</span>&#125;)</span><br><span class="line">    <span class="keyword">return</span> ifcompany[<span class="number">0</span>].get(<span class="string">'href'</span>)</span><br></pre></td></tr></table></figure>
<h4 id="查找股东页面url"><a class="markdownIt-Anchor" href="#查找股东页面url"></a> <strong>查找股东页面url</strong></h4>
<p>有了公司页面url，通过phantomjs来获取公司页面源代码，然后解析内容，获得指定公司的基本信息和所有股东信息</p>
<p>然后输入股东格名，获得股东页面url。<br>
<strong>在输入股东姓名时，需要注意python2的编码问题，从网页获得的股东姓名格式是unicode，而在Bash里输入的股东姓名是以string的形式，所以在这里需要对输入的股东姓名重新编码</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_company_info</span><span class="params">(company_url)</span>:</span><span class="comment">#获得公司信息和股东url</span></span><br><span class="line">    soup = get_content(driver, company_url)<span class="comment">#得到公司页面源代码</span></span><br><span class="line">    company = soup.select(<span class="string">'div.company_info_text &gt; div.ng-binding'</span>)[<span class="number">0</span>].get_text()</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"-----公司名称-----"</span></span><br><span class="line">    <span class="keyword">print</span> company</span><br><span class="line">    tzfs = soup.find_all(attrs=&#123;<span class="string">"event-name"</span>: <span class="string">"company-detail-investment"</span>&#125;)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"-----股东-----"</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(tzfs)):</span><br><span class="line">        tzf_split = tzfs[i].text.replace(<span class="string">"\n"</span>,<span class="string">""</span>).split()</span><br><span class="line">        tzf = <span class="string">' '</span>.join(tzf_split)</span><br><span class="line">        <span class="keyword">print</span> tzf</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"-------------"</span></span><br><span class="line">    holder_name = raw_input(<span class="string">'请输入股东姓名：\n'</span>).decode(<span class="string">'utf-8'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(tzfs)):</span><br><span class="line">        <span class="keyword">if</span> [holder_name] == tzfs[i].text.split():</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    holder_url = soup.find_all(attrs=&#123;<span class="string">"event-name"</span>: <span class="string">"company-detail-investment"</span>&#125;)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">'www.tianyancha.com'</span> + holder_url[i].get(<span class="string">'href'</span>)</span><br></pre></td></tr></table></figure>
<h4 id="获得股东信息"><a class="markdownIt-Anchor" href="#获得股东信息"></a> <strong>获得股东信息</strong></h4>
<p>接下来就获取到了股东信息，就结束了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_holder_info</span><span class="params">(human_url)</span>:</span><span class="comment">#获得股东信息</span></span><br><span class="line">    human_soup = get_content(driver, <span class="string">"http://"</span>+human_url)<span class="comment">#在这里卡了很久。。。。。。</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">"-------股东信息-------"</span></span><br><span class="line">    base_info = human_soup.find_all(attrs=&#123;<span class="string">"ng-if"</span>: <span class="string">"singleHumanBase"</span>&#125;)</span><br><span class="line">    <span class="keyword">print</span> base_info[<span class="number">0</span>].text</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"-----认识的人-----"</span></span><br><span class="line">    rpersons = human_soup.find_all(attrs=&#123;<span class="string">"ng-if"</span> : <span class="string">"relatedHuman.name"</span>&#125;)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(rpersons)):</span><br><span class="line">        rperson_split =rpersons[i].text.replace(<span class="string">"\n"</span>,<span class="string">""</span>).split()</span><br><span class="line">        rperson = <span class="string">' '</span>.join(rperson_split)</span><br><span class="line">        <span class="keyword">print</span> rperson</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"-----关联企业-----"</span></span><br><span class="line">    rcompanys = human_soup.find_all(attrs=&#123;<span class="string">"ng-bind-html"</span>: <span class="string">"node.name | trustHtml"</span>&#125;)</span><br><span class="line">    some_info = human_soup.select(<span class="string">'div.title'</span>)</span><br><span class="line">    state_infos = human_soup.find_all(attrs=&#123;<span class="string">"ng-class"</span>: <span class="string">"initStatusColor(node.regStatus);"</span>&#125;)</span><br><span class="line">    rate_infos = human_soup.select(<span class="string">'svg'</span>)</span><br><span class="line">    base_infos = human_soup.select(<span class="string">'div.search_base '</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(rcompanys)+<span class="number">1</span>):</span><br><span class="line">        state_info_split = state_infos[i<span class="number">-1</span>].text.replace(<span class="string">"\n"</span>,<span class="string">""</span>).split()</span><br><span class="line">        state_info = <span class="string">' '</span>.join(state_info_split)</span><br><span class="line">        rcompany_split =rcompanys[i<span class="number">-1</span>].text.replace(<span class="string">"\n"</span>,<span class="string">""</span>).split()</span><br><span class="line">        rcompany = <span class="string">' '</span>.join(rcompany_split)</span><br><span class="line">        rate_info = rate_infos[i<span class="number">-1</span>].text</span><br><span class="line">        rate_u = <span class="string">"评分"</span>.decode(<span class="string">'utf-8'</span>)</span><br><span class="line">        base_info_split = base_infos[i<span class="number">-1</span>].text.replace(rate_u,<span class="string">""</span>).split()</span><br><span class="line">        base_info = <span class="string">' '</span>.join(base_info_split)</span><br><span class="line">        some_info_1 = some_info[<span class="number">3</span>*i - <span class="number">3</span>].text.replace(<span class="string">" "</span>,<span class="string">""</span>)</span><br><span class="line">        some_info_2 = some_info[<span class="number">3</span>*i - <span class="number">2</span>].text.replace(<span class="string">" "</span>,<span class="string">""</span>)</span><br><span class="line">        some_info_3 = some_info[<span class="number">3</span>*i - <span class="number">1</span>].text.replace(<span class="string">" "</span>,<span class="string">""</span>)</span><br><span class="line">        <span class="keyword">print</span> rcompany + <span class="string">'\n'</span>+ some_info_1 + <span class="string">' '</span>+ some_info_2 + <span class="string">' '</span>+ some_info_3 + <span class="string">u' 状态: '</span> + state_info + <span class="string">' '</span> + rate_info + <span class="string">u' 位置:'</span> + base_info[<span class="number">0</span>:<span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<h3 id="整合-全部代码"><a class="markdownIt-Anchor" href="#整合-全部代码"></a> 整合------全部代码：</h3>
<p>总的来说，这仅仅是单页面的一个示例，而且还有很多地方语句写的不优美，以后再花时间改进。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> time, urllib</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.desired_capabilities <span class="keyword">import</span> DesiredCapabilities</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">driver_open</span><span class="params">()</span>:</span></span><br><span class="line">    dcap = dict(DesiredCapabilities.PHANTOMJS)</span><br><span class="line">    dcap[<span class="string">"phantomjs.page.settings.userAgent"</span>] = (</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0"</span></span><br><span class="line">    )</span><br><span class="line">    driver = webdriver.PhantomJS(desired_capabilities=dcap)</span><br><span class="line">    <span class="keyword">return</span> driver</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_content</span><span class="params">(driver,url)</span>:</span></span><br><span class="line">    driver.get(url)</span><br><span class="line">    <span class="comment">#等待2秒，根据动态网页加载耗时自定义</span></span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 获取网页内容</span></span><br><span class="line">    content = driver.page_source.encode(<span class="string">'utf-8'</span>)</span><br><span class="line">    soup = BeautifulSoup(content, <span class="string">'lxml'</span>)</span><br><span class="line">    <span class="keyword">return</span> soup</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">search_url</span><span class="params">(keyname)</span>:</span><span class="comment">#查找公司url</span></span><br><span class="line">    key = urllib.quote(keyname)</span><br><span class="line">    search_url = <span class="string">'http://www.tianyancha.com/search?key='</span> + key + <span class="string">'&amp;checkFrom=searchBox'</span></span><br><span class="line">    res_soup = get_content(driver, search_url) <span class="comment">#得到搜索页代码</span></span><br><span class="line">    ifname = res_soup.find_all(attrs=&#123;<span class="string">"ng-bind-html"</span>: <span class="string">"node.name | trustHtml"</span>&#125;)</span><br><span class="line">    name = ifname[<span class="number">0</span>].text </span><br><span class="line">    ifcompany = res_soup.find_all(attrs=&#123;<span class="string">"ng-click"</span>: <span class="string">"$event.preventDefault();goToCompany(node.id);inClick=true;"</span>&#125;)</span><br><span class="line">    <span class="keyword">return</span> ifcompany[<span class="number">0</span>].get(<span class="string">'href'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_company_info</span><span class="params">(company_url)</span>:</span><span class="comment">#获得公司信息和股东url</span></span><br><span class="line">    soup = get_content(driver, company_url)</span><br><span class="line">    company = soup.select(<span class="string">'div.company_info_text &gt; div.ng-binding'</span>)[<span class="number">0</span>].get_text()</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"-----公司名称-----"</span></span><br><span class="line">    <span class="keyword">print</span> company</span><br><span class="line">    tzfs = soup.find_all(attrs=&#123;<span class="string">"event-name"</span>: <span class="string">"company-detail-investment"</span>&#125;)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"-----股东-----"</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(tzfs)):</span><br><span class="line">        tzf_split = tzfs[i].text.replace(<span class="string">"\n"</span>,<span class="string">""</span>).split()</span><br><span class="line">        tzf = <span class="string">' '</span>.join(tzf_split)</span><br><span class="line">        <span class="keyword">print</span> tzf</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"-------------"</span></span><br><span class="line">    holder_name = raw_input(<span class="string">'请输入股东姓名：\n'</span>).decode(<span class="string">'utf-8'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(tzfs)):</span><br><span class="line">        <span class="keyword">if</span> [holder_name] == tzfs[i].text.split():</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    holder_url = soup.find_all(attrs=&#123;<span class="string">"event-name"</span>: <span class="string">"company-detail-investment"</span>&#125;)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">'www.tianyancha.com'</span> + holder_url[i].get(<span class="string">'href'</span>)  </span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_holder_info</span><span class="params">(human_url)</span>:</span><span class="comment">#获得股东信息</span></span><br><span class="line">    human_soup = get_content(driver, <span class="string">"http://"</span>+human_url)<span class="comment">#在这里卡了很久。。。。。。</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">"-------股东信息-------"</span></span><br><span class="line">    base_info = human_soup.find_all(attrs=&#123;<span class="string">"ng-if"</span>: <span class="string">"singleHumanBase"</span>&#125;)</span><br><span class="line">    <span class="keyword">print</span> base_info[<span class="number">0</span>].text</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"-----认识的人-----"</span></span><br><span class="line">    rpersons = human_soup.find_all(attrs=&#123;<span class="string">"ng-if"</span> : <span class="string">"relatedHuman.name"</span>&#125;)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(rpersons)):</span><br><span class="line">        rperson_split =rpersons[i].text.replace(<span class="string">"\n"</span>,<span class="string">""</span>).split()</span><br><span class="line">        rperson = <span class="string">' '</span>.join(rperson_split)</span><br><span class="line">        <span class="keyword">print</span> rperson</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"-----关联企业-----"</span></span><br><span class="line">    rcompanys = human_soup.find_all(attrs=&#123;<span class="string">"ng-bind-html"</span>: <span class="string">"node.name | trustHtml"</span>&#125;)</span><br><span class="line">    some_info = human_soup.select(<span class="string">'div.title'</span>)</span><br><span class="line">    state_infos = human_soup.find_all(attrs=&#123;<span class="string">"ng-class"</span>: <span class="string">"initStatusColor(node.regStatus);"</span>&#125;)</span><br><span class="line">    rate_infos = human_soup.select(<span class="string">'svg'</span>)</span><br><span class="line">    base_infos = human_soup.select(<span class="string">'div.search_base '</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(rcompanys)+<span class="number">1</span>):</span><br><span class="line">        state_info_split = state_infos[i<span class="number">-1</span>].text.replace(<span class="string">"\n"</span>,<span class="string">""</span>).split()</span><br><span class="line">        state_info = <span class="string">' '</span>.join(state_info_split)</span><br><span class="line">        rcompany_split =rcompanys[i<span class="number">-1</span>].text.replace(<span class="string">"\n"</span>,<span class="string">""</span>).split()</span><br><span class="line">        rcompany = <span class="string">' '</span>.join(rcompany_split)</span><br><span class="line">        rate_info = rate_infos[i<span class="number">-1</span>].text</span><br><span class="line">        rate_u = <span class="string">"评分"</span>.decode(<span class="string">'utf-8'</span>)</span><br><span class="line">        base_info_split = base_infos[i<span class="number">-1</span>].text.replace(rate_u,<span class="string">""</span>).split()</span><br><span class="line">        base_info = <span class="string">' '</span>.join(base_info_split)</span><br><span class="line">        some_info_1 = some_info[<span class="number">3</span>*i - <span class="number">3</span>].text.replace(<span class="string">" "</span>,<span class="string">""</span>)</span><br><span class="line">        some_info_2 = some_info[<span class="number">3</span>*i - <span class="number">2</span>].text.replace(<span class="string">" "</span>,<span class="string">""</span>)</span><br><span class="line">        some_info_3 = some_info[<span class="number">3</span>*i - <span class="number">1</span>].text.replace(<span class="string">" "</span>,<span class="string">""</span>)</span><br><span class="line">        <span class="keyword">print</span> rcompany + <span class="string">'\n'</span>+ some_info_1 + <span class="string">' '</span>+ some_info_2 + <span class="string">' '</span>+ some_info_3 + <span class="string">u' 状态: '</span> + state_info + <span class="string">' '</span> + rate_info + <span class="string">u' 位置:'</span> + base_info[<span class="number">0</span>:<span class="number">2</span>]</span><br><span class="line">        </span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        driver = driver_open()</span><br><span class="line">    <span class="keyword">except</span> Exception, e:</span><br><span class="line">        <span class="keyword">print</span> e</span><br><span class="line">    company_name=raw_input(<span class="string">"请输入公司名称:\n"</span>)</span><br><span class="line">    company_url = search_url(company_name)</span><br><span class="line">    human_url = get_company_info(company_url)</span><br><span class="line">    get_holder_info(human_url)</span><br><span class="line">    driver.close()</span><br></pre></td></tr></table></figure>
<p><strong>这里以腾讯为例：</strong><br>
<img src="https://i.postimg.cc/Y0d84hn3/0067n1-Rcgy1fe8as329n8j30rr0jn79p.jpg" alt="示例"></p>

      
    </div>

    
      
      

  <div class="post-copyright">
    <p class="copyright-item">
      <span>作者: </span>
      <span>Sikasjc</span>
    </p>
    <p class="copyright-item">
      <span>链接: </span>
      <a href="http://sikasjc.github.io/2017/04/02/pachong/">http://sikasjc.github.io/2017/04/02/pachong/</a>
    </p>
    <p class="copyright-item lincese">
      
      <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>
    </p>
  </div>



      
      
    

    
      <footer class="post-footer">
        
          <div class="post-tags">
            
              <a href="/tags/python/">python</a>
            
              <a href="/tags/爬虫/">爬虫</a>
            
          </div>
        
        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2017/04/03/format/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">python format函数</span>
        <span class="prev-text nav-mobile">上一篇</span>
      </a>
    
    
      <a class="next" href="/2017/04/02/intersection/">
        <span class="next-text nav-default">leetcode 349. Intersection of Two Arrays python</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

      </footer>
    

  </article>


          </div>
          
  <div class="comments" id="comments">
    
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zMzQzMy85OTg5">
        <noscript>为正常使用来必力评论功能请激活JavaScript</noscript>
      </div>  
    
  </div>

        </div>  
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:sikasjc@163.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/sikasjc" class="iconfont icon-github" title="github"></a>
        
      
    
      
        
          <a href="http://weibo.com/u/5605720030" class="iconfont icon-weibo" title="weibo"></a>
        
      
    
      
        
          <a href="https://www.zhihu.com/people/si-qia-sika" class="iconfont icon-zhihu" title="zhihu"></a>
        
      
    
      
    
      
    
      
    
      
    
    
    
  </div>


<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a>
  </span>
  
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2017 - 
    
    2019

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Sikasjc</span>
  </span>
</div>
      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    
  
  

  
   <script type="text/javascript">
	(function(d, s) {
       var j, e = d.getElementsByTagName(s)[0];

       if (typeof LivereTower === 'function') { return; }

       j = d.createElement(s);
       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
       j.async = true;

       e.parentNode.insertBefore(j, e);
   })(document, 'script');
  </script>




    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  


    <script type="text/javascript" src="/js/src/even.js?v=2.6.0"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=2.6.0"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css" integrity="sha384-TEMocfGvRuD1rIAacqrknm5BQZ7W7uWitoih+jMNFXQIbNl16bO8OZmylH/Vi/Ei" crossorigin="anonymous">
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  </body>
</html>
